# GClus: Enforcing Explicit Size Constraints in Graph Clustering through Structural Refinement

## Overview

This repository contains the experimental materials and supplementary documentation for the paper:

**GClus: Enforcing Explicit Size Constraints in Graph Clustering through Structural Refinement**

GClus is a graph clustering algorithm that integrates strict, user-defined size limits into the community detection process.  
It combines structural metrics (k-truss, clique density, and conductance) with iterative split-and-merge refinements to ensure that communities remain both structurally cohesive and balanced in size.

---

## A) Datasets

The evaluation of GClus was conducted using a diverse collection of real-world and synthetic benchmark networks.

### Real-World Networks

- **Dolphins**  
  Introduced by Lusseau et al. (2003), this network represents associations among 62 bottlenose dolphins through 159 undirected edges.  
  It features a moderate sparsity level and a known ground truth of two communities, serving as a benchmark for assessing constraint enforcement.

- **Karate Club**  
  Proposed by Zachary (1977), this dataset models social relationships among 34 members connected by 78 edges.  
  It naturally divides into two factions and is widely used to evaluate clustering stability and accuracy.

- **Polbooks**  
  Based on co-purchasing patterns of political books (Newman, 2006), this network contains 105 nodes and 441 edges distributed across three main groups.  
  Its higher density tests the algorithm’s ability to maintain structural integrity under size constraints.

- **Les Misérables**  
  A character co-occurrence network extracted from Victor Hugo’s novel, composed of 77 nodes and 254 edges.  
  Since it lacks predefined community labels, it is used to evaluate GClus’s ability to infer structure in unlabeled, text-derived graphs.

### Synthetic Networks

Synthetic benchmarks were generated with explicit size restrictions to test the robustness of GClus under varying densities and geometries.

- **Aggregation** – Clusters of uneven but well-separated group sizes.  
- **Bridge** – Two densely connected clusters linked by a thin bridge, used to test the merge/split balance.  
- **Compound** – Multiple communities with varying interconnectivity.  
- **Flame** – Two clusters with irregular, flame-like shapes.  
- **Jain** – Two well-separated “moon-shaped” clusters.  
- **Spiral** – Three intertwined spiral clusters.  
- **Two Diamonds** – Two diamond-shaped groups with strict size requirements.  
- **Sticks** – Three elongated communities with linear structures.  
- **Five Cluster** – Five clusters of different sizes for scalability testing.  
- **Noisy Circles** – Circular clusters with injected noise, used to evaluate performance under uncertain community boundaries.

---

## B) Experimental Environment

All experiments were performed on a dedicated workstation to ensure reproducibility and consistency.

### Hardware
- CPU: Intel Core i7-10510, 8 cores, up to 4.9 GHz  
- RAM: 12 GB DDR4  
- Storage: 1 TB NVMe SSD

### Software
- Programming Language: Python 3.12  
- Environment Manager: Conda 24.9.1  
- Main Libraries: NetworkX, NumPy, SciPy

### Profiling Tools
Execution time (milliseconds) and memory consumption (kilobytes) were measured using Python’s built-in `time` module and the `memory_profiler` library.

---

## C) Cluster Structures

This appendix compares the cluster configurations generated by **GClus** and the **SMKNN** baseline algorithm on real-world networks such as *Karate*, *Dolphins*, and *Polbooks*.

- GClus produces compact and balanced clusters that precisely satisfy the specified size constraints.  
- SMKNN, although unconstrained, tends to achieve slightly higher modularity at the expense of uneven cluster sizes.

Figures included in the paper (not reproduced here) depict:
- (a–c) GClus results on Karate, Dolphins, and Polbooks.  
- (d–f) SMKNN results for the same datasets.

---

## D) Execution Time and Memory Usage

Performance analyses reveal that GClus introduces moderate computational overhead due to its iterative refinement process.

- On small networks (Karate, Dolphins), runtime differences between GClus and SMKNN remain within a few milliseconds (approximately 24–27 ms vs. 16–25 ms).  
- On medium-sized networks (Polbooks, Les Misérables), additional refinement increases runtime by about 10–30 ms and memory usage slightly, remaining competitive overall.  
- On larger synthetic datasets (Compound, Five Cluster, Spiral), runtime may double compared to SMKNN due to repeated balancing phases; however, the increase scales linearly with graph size.

In summary, GClus maintains computational efficiency while achieving strict adherence to size constraints, demonstrating scalability across various graph topologies.

---



